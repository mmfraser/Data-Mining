Intervals per Rule = 40
Rules per class = 1
Iterations = 10000
Training File = ˆ$­û
Test File = ˆ$­û
best on training set at iteration 0:  1.9019%
best on training set at iteration 100:  1.9019%
best on training set at iteration 200:  2.002%
best on training set at iteration 300:  2.002%
best on training set at iteration 400:  2.3023%
best on training set at iteration 500:  2.3023%
best on training set at iteration 600:  2.3023%
best on training set at iteration 700:  2.3023%
best on training set at iteration 800:  2.5025%
best on training set at iteration 900:  2.6026%
best on training set at iteration 1000:  2.6026%
best on training set at iteration 1100:  2.6026%
best on training set at iteration 1200:  2.7027%
best on training set at iteration 1300:  3.003%
best on training set at iteration 1400:  3.1031%
best on training set at iteration 1500:  3.1031%
best on training set at iteration 1600:  3.2032%
best on training set at iteration 1700:  3.5035%
best on training set at iteration 1800:  3.5035%
best on training set at iteration 1900:  3.5035%
best on training set at iteration 2000:  3.5035%
best on training set at iteration 2100:  3.8038%
best on training set at iteration 2200:  3.8038%
best on training set at iteration 2300:  4.004%
best on training set at iteration 2400:  4.004%
best on training set at iteration 2500:  4.004%
best on training set at iteration 2600:  4.004%
best on training set at iteration 2700:  4.004%
best on training set at iteration 2800:  4.004%
best on training set at iteration 2900:  4.004%
best on training set at iteration 3000:  4.004%
best on training set at iteration 3100:  4.004%
best on training set at iteration 3200:  4.6046%
best on training set at iteration 3300:  4.6046%
best on training set at iteration 3400:  4.6046%
best on training set at iteration 3500:  4.6046%
best on training set at iteration 3600:  4.6046%
best on training set at iteration 3700:  4.6046%
best on training set at iteration 3800:  4.6046%
best on training set at iteration 3900:  4.6046%
best on training set at iteration 4000:  4.6046%
best on training set at iteration 4100:  5.10511%
best on training set at iteration 4200:  5.10511%
best on training set at iteration 4300:  5.10511%
best on training set at iteration 4400:  6.00601%
best on training set at iteration 4500:  6.00601%
best on training set at iteration 4600:  6.00601%
best on training set at iteration 4700:  6.00601%
best on training set at iteration 4800:  6.10611%
best on training set at iteration 4900:  6.10611%
best on training set at iteration 5000:  6.10611%
best on training set at iteration 5100:  6.10611%
best on training set at iteration 5200:  6.10611%
best on training set at iteration 5300:  6.10611%
best on training set at iteration 5400:  6.10611%
best on training set at iteration 5500:  6.10611%
best on training set at iteration 5600:  6.20621%
best on training set at iteration 5700:  6.20621%
best on training set at iteration 5800:  6.20621%
best on training set at iteration 5900:  6.20621%
best on training set at iteration 6000:  6.20621%
best on training set at iteration 6100:  6.20621%
best on training set at iteration 6200:  6.20621%
best on training set at iteration 6300:  6.20621%
best on training set at iteration 6400:  6.20621%
best on training set at iteration 6500:  6.20621%
best on training set at iteration 6600:  6.20621%
best on training set at iteration 6700:  6.20621%
best on training set at iteration 6800:  6.20621%
best on training set at iteration 6900:  6.20621%
best on training set at iteration 7000:  6.20621%
best on training set at iteration 7100:  6.20621%
best on training set at iteration 7200:  6.20621%
best on training set at iteration 7300:  6.20621%
best on training set at iteration 7400:  6.20621%
best on training set at iteration 7500:  6.20621%
best on training set at iteration 7600:  6.20621%
best on training set at iteration 7700:  6.20621%
best on training set at iteration 7800:  6.20621%
best on training set at iteration 7900:  6.20621%
best on training set at iteration 8000:  6.20621%
best on training set at iteration 8100:  6.20621%
best on training set at iteration 8200:  6.20621%
best on training set at iteration 8300:  6.20621%
best on training set at iteration 8400:  6.20621%
best on training set at iteration 8500:  6.20621%
best on training set at iteration 8600:  6.20621%
best on training set at iteration 8700:  6.20621%
best on training set at iteration 8800:  6.20621%
best on training set at iteration 8900:  6.20621%
best on training set at iteration 9000:  6.20621%
best on training set at iteration 9100:  6.20621%
best on training set at iteration 9200:  6.20621%
best on training set at iteration 9300:  6.20621%
best on training set at iteration 9400:  6.20621%
best on training set at iteration 9500:  6.20621%
best on training set at iteration 9600:  6.20621%
best on training set at iteration 9700:  6.20621%
best on training set at iteration 9800:  6.20621%
best on training set at iteration 9900:  6.20621%

 10-[6  16]  16-[-0  13]  47-[-0  8]  56-[-0  6]  54-[3  7]  44-[-0  8]  43-[-0  4]  55-[-0  13]  41-[1  15]  62-[-0  -0]  1-[-0  7]  30-[2  11]  49-[-0  2]  21-[2  16]  7-[-0  1]  6-[-0  11]  35-[-0  9]  33-[3  13]  15-[-0  15]  6-[-0  2]  20-[1  4]  22-[-0  9]  12-[6  16]  19-[0  10]  23-[-0  8]  20-[1  12]  6-[-0  9]  15-[-0  10]  57-[-0  8]  16-[-0  6]  7-[-0  16]  47-[-0  2]  61-[1  15]  32-[-0  3]  16-[-0  9]  40-[-0  7]  21-[10  16]  46-[1  12]  9-[-0  13]  55-[-0  8] -> 0
 37-[7  16]  47-[-0  2]  26-[11  16]  8-[-0  3]  56-[-0  11]  1-[-0  7]  32-[-0  2]  48-[-0  4]  15-[-0  1]  28-[4  16]  1-[-0  8]  50-[-0  11]  23-[-0  8]  30-[1  13]  44-[14  16]  15-[-0  5]  45-[4  16]  39-[-0  1]  22-[-0  5]  49-[-0  16]  23-[-0  13]  51-[2  9]  56-[-0  7]  59-[3  6]  54-[1  13]  50-[-0  3]  59-[1  10]  21-[13  16]  47-[-0  5]  21-[4  16]  2-[-0  14]  55-[-0  7]  53-[15  16]  24-[-0  3]  15-[-0  8]  26-[7  16]  57-[-0  2]  8-[-0  9]  36-[1  16]  32-[-0  7] -> 1
 58-[6  13]  48-[-0  13]  32-[-0  1]  32-[-0  6]  23-[-0  9]  24-[-0  16]  59-[1  16]  1-[-0  7]  63-[-0  6]  49-[-0  7]  63-[-0  13]  9-[3  12]  20-[9  16]  61-[4  14]  48-[-0  6]  18-[1  3]  32-[-0  12]  48-[-0  11]  56-[-0  9]  25-[-0  15]  21-[1  14]  62-[-0  12]  22-[-0  9]  25-[-0  6]  31-[-0  6]  51-[2  15]  27-[1  9]  3-[14  16]  60-[4  15]  62-[-0  10]  20-[6  16]  6-[-0  3]  13-[2  9]  9-[5  8]  33-[-0  2]  1-[-0  12]  11-[3  8]  58-[9  15]  20-[5  16]  17-[-0  12] -> 2
 39-[-0  3]  3-[14  16]  45-[13  16]  14-[-0  13]  39-[-0  13]  55-[-0  7]  21-[1  15]  55-[-0  5]  63-[-0  15]  57-[0  13]  51-[2  11]  58-[4  14]  29-[2  13]  57-[0  8]  9-[5  16]  37-[8  16]  44-[-0  5]  38-[1  4]  61-[6  16]  13-[4  13]  8-[-0  7]  49-[2  7]  45-[12  16]  1-[-0  7]  42-[3  10]  50-[6  16]  7-[-0  8]  16-[-0  12]  39-[-0  15]  25-[-0  5]  47-[-0  5]  32-[-0  14]  59-[15  16]  17-[-0  13]  54-[1  11]  63-[-0  15]  16-[-0  15]  35-[-0  3]  46-[-0  10]  34-[-0  16] -> 3
 20-[-0  11]  20-[-0  11]  1-[-0  5]  43-[10  16]  44-[9  15]  1-[-0  8]  24-[-0  4]  19-[4  12]  5-[-0  9]  36-[5  12]  18-[7  16]  11-[2  16]  55-[-0  15]  37-[3  16]  31-[-0  15]  63-[-0  15]  56-[-0  16]  19-[5  16]  1-[-0  1]  18-[4  12]  19-[7  16]  43-[2  14]  13-[1  7]  14-[4  7]  29-[1  16]  48-[-0  15]  57-[-0  5]  31-[-0  16]  45-[12  15]  42-[1  12]  39-[-0  -0]  46-[1  10]  59-[1  14]  38-[1  6]  47-[-0  6]  58-[-0  3]  22-[1  15]  45-[7  16]  15-[-0  8]  53-[1  6] -> 4
 25-[3  15]  63-[-0  16]  21-[-0  5]  19-[-0  12]  53-[9  16]  19-[-0  14]  27-[6  16]  51-[3  15]  27-[3  15]  50-[1  15]  7-[-0  13]  58-[6  16]  59-[5  16]  49-[0  3]  31-[-0  10]  15-[-0  2]  55-[-0  12]  52-[0  6]  10-[15  16]  62-[-0  15]  8-[-0  1]  60-[4  16]  2-[4  15]  54-[1  5]  36-[6  8]  25-[0  12]  38-[3  6]  40-[-0  12]  11-[2  12]  28-[8  16]  42-[-0  9]  11-[7  16]  4-[9  16]  38-[-0  10]  37-[9  15]  42-[-0  8]  13-[1  10]  40-[-0  16]  9-[4  11]  40-[-0  5] -> 5
 12-[2  10]  59-[2  15]  12-[1  13]  15-[-0  15]  2-[-0  5]  20-[-0  11]  22-[-0  5]  21-[-0  13]  14-[-0  12]  6-[-0  3]  23-[-0  3]  13-[-0  4]  13-[-0  8]  63-[-0  3]  21-[-0  11]  56-[-0  15]  63-[-0  9]  1-[-0  4]  31-[-0  13]  31-[-0  3]  32-[-0  1]  8-[-0  14]  31-[-0  13]  13-[-0  7]  8-[-0  16]  11-[3  16]  12-[-0  15]  15-[-0  2]  23-[-0  7]  48-[-0  -0]  32-[-0  2]  1-[-0  7]  48-[-0  15]  17-[-0  13]  21-[-0  13]  40-[-0  12]  40-[-0  11]  6-[-0  14]  16-[-0  9]  39-[-0  7] -> 6
 18-[0  15]  44-[-0  1]  23-[-0  1]  20-[13  16]  18-[0  16]  10-[11  15]  50-[1  15]  63-[-0  13]  58-[2  16]  63-[-0  16]  19-[1  7]  2-[5  15]  61-[-0  12]  32-[-0  6]  13-[2  16]  12-[5  16]  21-[3  6]  7-[-0  8]  20-[3  16]  34-[10  16]  2-[6  16]  19-[1  16]  35-[2  16]  14-[-0  6]  3-[6  16]  13-[1  16]  34-[8  16]  15-[-0  3]  1-[1  13]  5-[1  13]  53-[-0  13]  12-[9  16]  46-[-0  9]  8-[-0  5]  32-[-0  11]  47-[-0  9]  11-[6  10]  14-[-0  2]  46-[-0  10]  35-[12  16] -> 7
 49-[-0  3]  60-[3  16]  34-[-0  15]  21-[5  9]  49-[-0  12]  24-[-0  8]  34-[-0  16]  17-[2  10]  10-[8  12]  13-[8  16]  47-[-0  5]  10-[2  13]  23-[-0  11]  28-[4  16]  25-[-0  11]  17-[2  15]  30-[1  4]  57-[-0  13]  39-[-0  10]  22-[8  13]  3-[7  14]  10-[9  16]  54-[-0  7]  33-[-0  11]  42-[-0  1]  5-[0  10]  41-[-0  14]  49-[-0  7]  55-[-0  15]  19-[4  9]  48-[-0  2]  11-[8  12]  18-[5  16]  63-[-0  12]  43-[2  11]  13-[14  16]  24-[-0  4]  57-[-0  12]  31-[-0  4]  29-[1  14] -> 8
 62-[-0  8]  17-[0  8]  16-[-0  2]  6-[-0  14]  40-[-0  7]  47-[-0  2]  5-[2  9]  29-[7  12]  19-[3  11]  51-[-0  10]  9-[2  12]  18-[12  16]  5-[1  9]  22-[1  4]  5-[1  3]  27-[5  13]  4-[2  15]  37-[4  14]  46-[5  13]  37-[1  5]  32-[-0  9]  7-[-0  6]  41-[-0  4]  33-[-0  4]  19-[2  16]  62-[-0  12]  40-[-0  2]  27-[4  14]  43-[-0  16]  31-[-0  4]  58-[10  14]  53-[2  16]  25-[-0  4]  36-[-0  16]  55-[-0  13]  33-[-0  7]  12-[4  15]  56-[-0  12]  53-[2  14]  12-[7  14] -> 9
ACCURACY on training set 6.20621%

TEST ACCURACY 4.66714%
